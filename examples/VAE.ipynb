{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pyro import distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import deepppl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variational AutoEncoder example showing the interface of *DeepPPL*\n",
    "This example uses two *NN* as black-box functions for which some parameters must be learned. Unlike the MLP example, no uncertainity is put on the NNs' parameters.\n",
    "\n",
    "Here is the source code of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networks {\n",
      "  Decoder decoder;\n",
      "  Encoder encoder;\n",
      "}\n",
      "\n",
      "data {\n",
      "    int nz;\n",
      "    int<lower=0, upper=1> x[28, 28];\n",
      "}\n",
      "parameters {\n",
      "    real z[*];\n",
      "}\n",
      "model {\n",
      "  real mu[_, _];\n",
      "  z ~ normal(0, 1);\n",
      "  mu = decoder(z);\n",
      "  x ~ bernoulli(mu);\n",
      "}\n",
      "\n",
      "guide {\n",
      "  real encoded[2, nz] = encoder(x);\n",
      "  real mu_z[*] = encoded[1];\n",
      "  real sigma_z[*] = encoded[2];\n",
      "  z ~ normal(mu_z, sigma_z);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('../tests/good/vae.stan', 'r') as source:\n",
    "    print(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, nx, nh, nz = 256, 28 * 28, 1024, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    train = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    test = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
    "                           num_workers=1, pin_memory=False)\n",
    "    train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "    test_loader = dataloader.DataLoader(test, **dataloader_args)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Architecture.\n",
    "Both  `Encoder` and `Decoder` are typical autoencoders except that the `Encoder` outputs a mean and variance for each instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lh = nn.Linear(nz, nh)\n",
    "        self.lx = nn.Linear(nh, nx)\n",
    "\n",
    "    def forward(self, z):\n",
    "        hidden = torch.relu(self.lh(z))\n",
    "        mu = self.lx(hidden)\n",
    "        return torch.sigmoid(mu.view(-1, 1, 28, 28))\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lh = torch.nn.Linear(nx, nh)\n",
    "        self.lz_mu = torch.nn.Linear(nh, nz)\n",
    "        self.lz_sigma = torch.nn.Linear(nh, nz)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, nx))\n",
    "        hidden = torch.relu(self.lh(x))\n",
    "        z_mu = self.lz_mu(hidden)\n",
    "        z_sigma = self.softplus(self.lz_sigma(hidden))\n",
    "        return z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepppl.PyroModel(model_file = '../tests/good/vae.stan', \n",
    "                           encoder = encoder, \n",
    "                           decoder = decoder)\n",
    "\n",
    "svi = model.svi(params = {'lr' : 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5395968a3941f1b199b9249f766511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154ef8f54942478394283565876fbb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88226d61de2c4d1ab6d73fee469b226b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7eed83fcb04acb83b0c054722c7e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0224ab02e69a45939900c6c163678055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(4), desc='epoch'):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    t = tqdm(enumerate(train_loader, 0), desc='mini_batch')\n",
    "    for j, (imgs, _) in t:\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(nz, imgs)\n",
    "        t.set_postfix(loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latent representation of `imgs`\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_loc, z_scale = encoder(imgs)\n",
    "\n",
    "decoded = decoder(dist.Normal(z_loc, z_scale).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot probabilities for each pixel\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(decoded[0].data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample one possible image\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dist.Bernoulli(decoded[0]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(sample.data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
