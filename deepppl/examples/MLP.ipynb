{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pyro import distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import deepppl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Basic example showing the interface of *DeepPPL*\n",
    "This example uses a NN: `MLP` adding uncertainity to its `parameters`\n",
    "\n",
    "The `DeepPPL` model should be built with the `mlp` as keyword argument\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```stan\n",
    "data {\n",
    "    int batch_size;\n",
    "    int <lower=0, upper=1> imgs[28,28,batch_size]; \n",
    "    int <lower=0, upper=10>  labels[batch_size];\n",
    "}\n",
    "\n",
    "networks {\n",
    "    MLP mlp with parameters:\n",
    "        l1.weight;\n",
    "        l1.bias;\n",
    "        l2.weight;\n",
    "        l2.bias;\n",
    "}\n",
    "\n",
    "prior\n",
    "{\n",
    "    mlp.l1.weight ~  normal(zeros(mlp.l1.weight$shape), ones(mlp.l1.weight$shape));\n",
    "    mlp.l1.bias ~ normal(zeros(mlp.l1.bias$shape), ones(mlp.l1.bias$shape));\n",
    "    mlp.l2.weight ~ normal(zeros(mlp.l2.weight$shape), ones(mlp.l2.weight$shape));\n",
    "    mlp.l2.bias ~  normal(zeros(mlp.l2.bias$shape), ones(mlp.l2.bias$shape));\n",
    "}\n",
    "\n",
    "guide parameters\n",
    "{\n",
    "    real l1wloc[mlp.l1.weight$shape];\n",
    "    real l1wscale[mlp.l1.weight$shape];\n",
    "    real l1bloc[mlp.l1.bias$shape];\n",
    "    real l1bscale[mlp.l1.bias$shape];\n",
    "    real l2wloc[mlp.l2.weight$shape];\n",
    "    real l2wscale[mlp.l2.weight$shape];\n",
    "    real l2bloc[mlp.l2.bias$shape];\n",
    "    real l2bscale[mlp.l2.bias$shape];\n",
    "}\n",
    "\n",
    "guide {\n",
    "    l1wloc = randn(l1wloc$shape);\n",
    "    l1wscale = randn(l1wscale$shape);\n",
    "    mlp.l1.weight ~  normal(l1wloc, softplus(l1wscale));\n",
    "    l1bloc = randn(l1bloc$shape);\n",
    "    l1bscale = randn(l1bscale$shape);\n",
    "    mlp.l1.bias ~ normal(l1bloc, softplus(l1bscale));\n",
    "    l2wloc = randn(l2wloc$shape);\n",
    "    l2wscale = randn(l2wscale$shape);\n",
    "    mlp.l2.weight ~ normal(l2wloc, softplus(l2wscale));\n",
    "    l2bloc = randn(l2bloc$shape);\n",
    "    l2bscale = randn(l2bscale$shape);\n",
    "    mlp.l2.bias ~ normal(l2bloc, softplus(l2bscale));\n",
    "}\n",
    "\n",
    "model {\n",
    "    real logits[batch_size];\n",
    "    logits = mlp(imgs);\n",
    "    labels ~ categorical_logits(logits);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, nx, nh, ny = 128, 28 * 28, 1024, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(nx, nh)\n",
    "        self.l2 = torch.nn.Linear(nh, ny)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.l1(x.view((-1, nx))))\n",
    "        yhat = self.l2(h)\n",
    "        return F.log_softmax(yhat, dim=-1)\n",
    "\n",
    "mlp = MLP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(batch_size):\n",
    "    train = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "    test = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "    dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
    "                        num_workers=3, pin_memory=False)\n",
    "    train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "    test_loader = dataloader.DataLoader(test, **dataloader_args)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_logits(logits):\n",
    "    return dist.Categorical(logits=logits)\n",
    "\n",
    "def predict(data, posterior):\n",
    "    predictions = [model(data) for model in posterior]\n",
    "    prediction = torch.stack(predictions).mean(dim=0)\n",
    "    return prediction.argmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build `DpPPPL` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae3ef26f1c945728c310c76066e2d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e90178e029443bca089b83f3cf58137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b8e32e5f774c8595e3897256691aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326df8ec3be948c29df39d9272a49f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "ANTLR runtime and generated code versions disagree: 4.7.2!=4.8\n",
      "ANTLR runtime and generated code versions disagree: 4.7.2!=4.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = loadData(batch_size)\n",
    "model = deepppl.PyroModel(model_file = '../tests/good/mlp.stan', mlp=mlp, categorical_logits=categorical_logits)\n",
    "svi = model.svi(params = {'lr' : 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using `svi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
      "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Iteration:99 Loss:407706.9223251343\n",
      "Epoch:0 Iteration:199 Loss:234124.97799873352\n",
      "Epoch:0 Iteration:299 Loss:152196.09954833984\n",
      "Epoch:0 Iteration:399 Loss:107269.11954212189\n",
      "Epoch:1 Iteration:99 Loss:61747.872787475586\n",
      "Epoch:1 Iteration:199 Loss:48487.588163375854\n",
      "Epoch:1 Iteration:299 Loss:36934.18068790436\n",
      "Epoch:1 Iteration:399 Loss:35177.457597732544\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    for j, (imgs, lbls) in enumerate(train_loader, 0):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(batch_size, imgs, lbls)\n",
    "        if (j+1) % 100 == 0:\n",
    "            print('Epoch:{} Iteration:{} Loss:{}'.format(epoch, j, loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute a posterior distribution\n",
    "In this case, the distribution is a distribution over possible MLPs. \n",
    "Each MLP will give a prediction and the uncertainity can be seen in the distribution of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = svi.posterior(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "For each element in the testset, we expect the accuracy to be higher than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    accuracy = (predict(images, posterior) == labels).type(torch.float).mean()\n",
    "    assert accuracy > 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a single batch can be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 8, 0, 9, 9, 2, 9, 7, 2, 1, 5, 0, 5, 7, 7, 0],\n",
       "       grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(images, posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
