{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pyro import distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import deepppl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variational AutoEncoder example showing the interface of *DeepPPL*\n",
    "This example uses two *NN* as black-box functions for which some parameters must be learned. Unlike the MLP example, no uncertainity is put on the NNs' parameters.\n",
    "\n",
    "An important feature used for this example is the `batch_size`  parameter of the distribution functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` stan\n",
    "data {\n",
    "    int x;\n",
    "    int nz;\n",
    "    int batch_size;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "parameters {\n",
    "    int latent;\n",
    "}\n",
    "\n",
    "networks {\n",
    "    Decoder decoder;\n",
    "    Encoder encoder;\n",
    "}\n",
    "\n",
    "guide {\n",
    "    real encoded[2];\n",
    "    real mu;\n",
    "    real sigma;\n",
    "    encoded = encoder(x);\n",
    "    mu = encoded[1];\n",
    "    sigma = encoded[2];\n",
    "    latent ~ normal(mu, sigma, batch_size);\n",
    "}\n",
    "\n",
    "model {\n",
    "    int loc_img;\n",
    "    latent ~ normal(zeros(nz), ones(nz), batch_size);\n",
    "    loc_img = decoder(latent);\n",
    "    x ~ Bernoulli(loc_img);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, nx, nh, nz = 256, 28 * 28, 1024, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    train = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    test = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
    "                           num_workers=1, pin_memory=False)\n",
    "    train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "    test_loader = dataloader.DataLoader(test, **dataloader_args)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Architecture.\n",
    "Both  `Encoder` and `Decoder` are typical autoencoders except that the `Encoder` outputs a mean and variance for each instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lh = nn.Linear(nz, nh)\n",
    "        self.lx = nn.Linear(nh, nx)\n",
    "\n",
    "    def forward(self, z):\n",
    "        hidden = torch.relu(self.lh(z))\n",
    "        mu = self.lx(hidden)\n",
    "        return torch.sigmoid(mu.view(-1, 1, 28, 28))\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lh = torch.nn.Linear(nx, nh)\n",
    "        self.lz_mu = torch.nn.Linear(nh, nz)\n",
    "        self.lz_sigma = torch.nn.Linear(nh, nz)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, nx))\n",
    "        hidden = torch.relu(self.lh(x))\n",
    "        z_mu = self.lz_mu(hidden)\n",
    "        z_sigma = self.softplus(self.lz_sigma(hidden))\n",
    "        return z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTLR runtime and generated code versions disagree: 4.7.2!=4.8\n",
      "ANTLR runtime and generated code versions disagree: 4.7.2!=4.8\n"
     ]
    }
   ],
   "source": [
    "model = deepppl.PyroModel(model_file = '../tests/good/vae.stan', \n",
    "                           encoder = encoder, \n",
    "                           decoder = decoder)\n",
    "\n",
    "svi = model.svi(params = {'lr' : 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb05e947b81944aaa9340a98ba04c492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ab0f7a249c4df19fe9780f5a855e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6d1c2293274c05ba25f4575af9d4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09d649c02c14851876dbccaa20dd85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aed24fa6a141c29caee13c5adcb30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(4), desc='epoch'):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    t = tqdm(enumerate(train_loader, 0), desc='mini_batch')\n",
    "    for j, (imgs, _) in t:\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(nz, imgs)\n",
    "        t.set_postfix(loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latent representation of `imgs`\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_loc, z_scale = encoder(imgs)\n",
    "\n",
    "decoded = decoder(dist.Normal(z_loc, z_scale).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot probabilities for each pixel\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(decoded[0].data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample one possible image\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dist.Bernoulli(decoded[0]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(sample.data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
