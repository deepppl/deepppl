{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pyro import distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import deepppl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variational AutoEncoder example showing the interface of *DeepPPL*\n",
    "This example uses two *NN* as black-box functions for which some parameters must be learned. Unlike the MLP example, no uncertainity is put on the NNs' parameters.\n",
    "\n",
    "An important feature used for this example is the `batch_size`  parameter of the distribution functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` stan\n",
    "data {\n",
    "    int x;\n",
    "    int nz;\n",
    "    int batch_size;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "parameters {\n",
    "    int latent;\n",
    "}\n",
    "\n",
    "networks {\n",
    "    Decoder decoder;\n",
    "    Encoder encoder;\n",
    "}\n",
    "\n",
    "guide {\n",
    "    real encoded[2];\n",
    "    real mu;\n",
    "    real sigma;\n",
    "    encoded = encoder(x);\n",
    "    mu = encoded[1];\n",
    "    sigma = encoded[2];\n",
    "    latent ~ normal(mu, sigma, batch_size);\n",
    "}\n",
    "\n",
    "model {\n",
    "    int loc_img;\n",
    "    latent ~ normal(zeros(nz), ones(nz), batch_size);\n",
    "    loc_img = decoder(latent);\n",
    "    x ~ Bernoulli(loc_img);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, nx, nh, nz = 256, 28 * 28, 1024, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    train = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    test = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
    "                           num_workers=1, pin_memory=False)\n",
    "    train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "    test_loader = dataloader.DataLoader(test, **dataloader_args)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Architecture.\n",
    "Both  `Encoder` and `Decoder` are typical autoencoders except that the `Encoder` outputs a mean and variance for each instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lh = nn.Linear(nz, nh)\n",
    "        self.lx = nn.Linear(nh, nx)\n",
    "\n",
    "    def forward(self, z):\n",
    "        hidden = torch.relu(self.lh(z))\n",
    "        mu = self.lx(hidden)\n",
    "        return torch.sigmoid(mu.view(-1, 1, 28, 28))\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lh = torch.nn.Linear(nx, nh)\n",
    "        self.lz_mu = torch.nn.Linear(nh, nz)\n",
    "        self.lz_sigma = torch.nn.Linear(nh, nz)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, nx))\n",
    "        hidden = torch.relu(self.lh(x))\n",
    "        z_mu = self.lz_mu(hidden)\n",
    "        z_sigma = self.softplus(self.lz_sigma(hidden))\n",
    "        return z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepppl.DppplModel(model_file = '../tests/good/vae.stan', \n",
    "                           encoder = encoder, \n",
    "                           decoder = decoder)\n",
    "\n",
    "svi = model.svi(params = {'lr' : 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb650c69aa64a5eb7ee4bb75062b1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2c16861de74d6781a04b307d311c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d790e15dc74e68a64db20c13d84b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1876dd04ba45483bae482684b36a4c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eba806d4d344181ae84909357a64c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(4), desc='epoch'):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    t = tqdm(enumerate(train_loader, 0), desc='mini_batch')\n",
    "    for j, (imgs, _) in t:\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(nz, imgs)\n",
    "        t.set_postfix(loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latent representation of `imgs`\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_loc, z_scale = encoder(imgs)\n",
    "\n",
    "decoded = decoder(dist.Normal(z_loc, z_scale).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot probabilities for each pixel\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(decoded[0].data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample one possible image\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dist.Bernoulli(decoded[0]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAACzCAYAAABPXD2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABbNJREFUeJzt3T9rVEscx+GTeA0p1CJVtIsRTCFGSJEihWAjEu2tBFvBMvgWfAu+AP+QMp2tRUAstBM2jWIZBVFBEcne4hYXnInu5uzJ7jd5nvLHbBxUPgzMOdmpfr/fbwCYaNPj3gAAfyfWAAHEGiCAWAMEEGuAAGINEECsAQKINUAAsQYIINYAAcQaIIBYAwQQa4AAYg0QQKwBAog1QACxBggg1gABxBoggFgDBBBrgABiDRBArAECiDVAALEGCCDWAAHEGiCAWAMEEGuAAGINEECsAQKINUCAf8a9AWAy/Pr1q5g9evSouvbjx4/FbG5urpjdv3+//cZomsbJGiCCWAMEEGuAAGINEECsAQJ4GqRjU1NTrT7f7/db/cza56HmwYMHxezp06fVtaurq8VsbW1t5Hvif07WAAHEGiCAWAMEEGuAAFN9N1Cdql0GDvNX3vbz8Lt3795V54uLi8VsY2Ojuvbhw4ej3BIDcLIGCCDWAAHEGiCAWAMEEGuAAJ4GgWPm7du31fnKykox+/r1a3XtiRMnRrqnP+n1esVsYWGhuvbkyZNdb2dsnKwBAog1QACxBggg1gAB/D7rEeni91YP+3PdFTOInZ2d6vzmzZvF7DAvEvezvLxczDY3N6trb9261fV2xsbJGiCAWAMEEGuAAGINEECsAQJ4GuQAuvhCgWF46oM2lpaWqvO9vb1i9uPHj+ra2dnZke6paZpmd3e3Oq+9Qn716tWR//mTzskaIIBYAwQQa4AAYg0QwAXjGLS9INzvgtLFI4O4cOFCdf7+/ftitr29XV177dq1ke6paZpma2urOq9dMJ45c2bkf/6kc7IGCCDWAAHEGiCAWAMEEGuAAL7d/AC6eF287c8c9uf6Z+d3r1+/LmZ3796trn38+HExqz1lst+3jb969aqY7feESe3V9k+fPlXXHmVO1gABxBoggFgDBBBrgABeN/+Drr5ZvO3vwx6Gi0QGdeXKlWJ2586d6tr19fVidv78+WL2+fPn6uffvHkz8L5u37498NqjzMkaIIBYAwQQa4AAYg0QwBuME6KrNxihCz9//ixmvV6vmH348KH6+cXFxWJ2/fr16tp79+4Vs42Njb9t8chxsgYIINYAAcQaIIBYAwQQa4AAXjc/Qg7zNXaOt5mZmWJ26dKlgWZN0zTfv38vZt++fauurb3Gfhw5WQMEEGuAAGINEECsAQJ43XzCdfU7tWGcdnZ2itnFixera798+VLMTp06NfI9TTona4AAYg0QQKwBAog1QACxBgjgdfMD8Fo3tPPs2bOB187Ozna4kxxO1gABxBoggFgDBBBrgAAuGA+g7WVi2wtKl5mke/HiRTHz//rPnKwBAog1QACxBggg1gABxBoggKdBJsR+XzLghpxke3t71Xntm8zX1ta63k40J2uAAGINEECsAQKINUAAF4xj4NKQ46LX61XnL1++LGaXL1+urp2edqZsGidrgAhiDRBArAECiDVAALEGCOBpkAmx3+vmNZ4mIcWTJ0+q89r/4c3NzepaT4P8x98CQACxBggg1gABxBoggAvGMRjmMnGYz7t4ZNI8f/68Op+bmytmZ8+e7Xo70ZysAQKINUAAsQYIINYAAcQaIICnQQ6g9jRGV09i1H5u26dJ4LCcO3euOp+fny9mp0+f7no70ZysAQKINUAAsQYIINYAAVwwHkDby8RhPn+Yl5kwaktLS9X5jRs3Dnkn+ZysAQKINUAAsQYIINYAAcQaIMBU36MFTdMc7lMXnvAAhuVkDRBArAECiDVAALEGCOCCESCAkzVAALEGCCDWAAHEGiCAWAMEEGuAAGINEECsAQKINUAAsQYIINYAAcQaIIBYAwQQa4AAYg0QQKwBAog1QACxBggg1gABxBoggFgDBBBrgABiDRBArAECiDVAALEGCCDWAAHEGiCAWAMEEGuAAP8CxzQK6zFAIlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(sample.data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
