{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pyro import distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import deepppl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variational AutoEncoder example showing the interface of *DeepPPL*\n",
    "This example uses two *NN* as black-box functions for which some parameters must be learned. Unlike the MLP example, no uncertainity is put on the NNs' parameters.\n",
    "\n",
    "Here is the source code of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networks {\n",
      "  Decoder decoder;\n",
      "  Encoder encoder;\n",
      "}\n",
      "\n",
      "data {\n",
      "    int nz;\n",
      "    int<lower=0, upper=1> x[28, 28];\n",
      "}\n",
      "parameters {\n",
      "    real z[*];\n",
      "}\n",
      "model {\n",
      "  real mu[*];\n",
      "  z ~ normal(0, 1);\n",
      "  mu = decoder(z);\n",
      "  x ~ bernoulli(mu);\n",
      "}\n",
      "\n",
      "guide {\n",
      "  real encoded[2, nz] = encoder(x);\n",
      "  real mu_z[*] = encoded[1];\n",
      "  real sigma_z[*] = encoded[2];\n",
      "  z ~ normal(mu_z, sigma_z);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('../tests/good/vae.stan', 'r') as source:\n",
    "    print(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, nx, nh, nz = 256, 28 * 28, 1024, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    train = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    test = MNIST(os.environ.get(\"DATA_DIR\", '.') + \"/data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),  # ToTensor does min-max normalization.\n",
    "    ]), )\n",
    "\n",
    "    dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
    "                           num_workers=1, pin_memory=False)\n",
    "    train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "    test_loader = dataloader.DataLoader(test, **dataloader_args)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Architecture.\n",
    "Both  `Encoder` and `Decoder` are typical autoencoders except that the `Encoder` outputs a mean and variance for each instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lh = nn.Linear(nz, nh)\n",
    "        self.lx = nn.Linear(nh, nx)\n",
    "\n",
    "    def forward(self, z):\n",
    "        hidden = torch.relu(self.lh(z))\n",
    "        mu = self.lx(hidden)\n",
    "        return torch.sigmoid(mu.view(-1, 1, 28, 28))\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lh = torch.nn.Linear(nx, nh)\n",
    "        self.lz_mu = torch.nn.Linear(nh, nz)\n",
    "        self.lz_sigma = torch.nn.Linear(nh, nz)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, nx))\n",
    "        hidden = torch.relu(self.lh(x))\n",
    "        z_mu = self.lz_mu(hidden)\n",
    "        z_sigma = self.softplus(self.lz_sigma(hidden))\n",
    "        return z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepppl.PyroModel(model_file = '../tests/good/vae.stan', \n",
    "                           encoder = encoder, \n",
    "                           decoder = decoder)\n",
    "\n",
    "svi = model.svi(params = {'lr' : 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e29d6881431489888b49474b9cc39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8e641a735845c49b9f1a1d8d9dff71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86daaaa02b2f4e2ebfbc29b5661d77fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3102eaccfda044dca77f7b5660d2bf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1982abe5994381866d253843a56724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='mini_batch', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(4), desc='epoch'):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    t = tqdm(enumerate(train_loader, 0), desc='mini_batch')\n",
    "    for j, (imgs, _) in t:\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(nz, imgs)\n",
    "        t.set_postfix(loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latent representation of `imgs`\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_loc, z_scale = encoder(imgs)\n",
    "\n",
    "decoded = decoder(dist.Normal(z_loc, z_scale).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot probabilities for each pixel\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(decoded[0].data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample one possible image\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dist.Bernoulli(decoded[0]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAACzCAYAAABPXD2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABRJJREFUeJzt3bFKm10cx/HXFwVbRAS7teoF9BJ06Oai1+BQcHZx6ODqVJeCU++hUDcROgXBRZx0ctChi4ggVF1M3gs4J75Jkxh/8fMZ/5yUA5Evhz7Pk2es1Wq1/gHgRft32BsA4P+JNUAAsQYIINYAAcQaIIBYAwQQa4AAYg0QQKwBAog1QACxBggg1gABxBoggFgDBBBrgABiDRBArAECiDVAALEGCCDWAAHEGiCAWAMEEGuAAGINEECsAQKINUAAsQYIMD7sDYy6sbGxYtZqtTpa124tPJfFxcXqvNlsFrNfv34Vszdv3vR9T6+VkzVAALEGCCDWAAHEGiCAC4x90u4CYa9rYZja/a0eHR0Vs69fvxazra2tvu/ptXKyBggg1gABxBoggFgDBBBrgADuBumTbh4L7/QRdEjy8+fPYvbly5fq2vFx6emWkzVAALEGCCDWAAHEGiCA/+XvE79HzWt3fHxczGq/e83fcbIGCCDWAAHEGiCAWAMEEGuAAO4G6ZN2d314uznQD07WAAHEGiCAWAMEEGuAAC4w9smg3m7ut69Jtr+/X52vrq4+807yOVkDBBBrgABiDRBArAECiDVAAHeD9EmvbzeHUXR+fj7sLYwMJ2uAAGINEECsAQKINUCAsZZnlwfK71mTbGlpqTo/PDzs6POzs7PV+dXV1V/v6bVysgYIINYAAcQaIIBYAwQQa4AAHjcfsG7u/ICXZn19vTo/OzsrZjc3N8Xs+vq6+vmLi4titrCw0OXuXhcna4AAYg0QQKwBAog1QACPmw/BoC4w+ip5Lh8/fixmtYuO7Xz//r2Yff78uac9jTona4AAYg0QQKwBAog1QABPMA6YpxUZRSsrK8Xs9PS0488fHBwUMxcYn+ZkDRBArAECiDVAALEGCCDWAAE8bj4Evd4h4itj2BqNRjH79OlTMWs2m9XPT01NFbPb29ue9zXKnKwBAog1QACxBggg1gABXGAcsEE8bu4r4yX68OFDMfv9+3d1rQuM3XOyBggg1gABxBoggFgDBBBrgABePjBgtTs3vJCA1+7x8bGY3d3dVde+fft20NuJ4GQNEECsAQKINUAAsQYI4AJjoHYXKD2GToraxcTd3d3q2s3NzUFvJ4KTNUAAsQYIINYAAcQaIIBYAwTw8oEBq9250c0j6L0+ru7r5bl08/KB2t/l3Nxcde3l5WVvGxsRTtYAAcQaIIBYAwQQa4AALjC+EC4aku7bt2/FbGNjo7q29jc8MTFRXbuzs1PM1tbWqmunp6ef2mI0J2uAAGINEECsAQKINUAAsQYI4G6QIej0EfRu18IwPTw8FLN3795V1/7586eYtbsjamZmppidnJxU187Pzz+1xWhO1gABxBoggFgDBBBrgADebj4Evf5Gtbeb8xJNTk4Ws+Xl5eraHz9+dPzvvn//vpiN8oXEdpysAQKINUAAsQYIINYAAcQaIIC7QV4Id3Iwira3t6vz+/v7YtZoNKpr9/b2+rqnVE7WAAHEGiCAWAMEEGuAAH7PGiCAkzVAALEGCCDWAAHEGiCAWAMEEGuAAGINEECsAQKINUAAsQYIINYAAcQaIIBYAwQQa4AAYg0QQKwBAog1QACxBggg1gABxBoggFgDBBBrgABiDRBArAECiDVAALEGCCDWAAHEGiCAWAMEEGuAAGINEECsAQKINUAAsQYIINYAAcQaIIBYAwQQa4AAYg0QQKwBAog1QID/AKt18ecicZMiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(sample.data.squeeze().numpy())\n",
    "ax2.imshow(imgs[0].squeeze().numpy())\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
